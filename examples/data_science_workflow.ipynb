{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bundestag Protocol Data Science Workflow\n",
    "\n",
    "This notebook demonstrates how to work with extracted Bundestag protocol data using pandas and the specialized helper modules provided with the Bundestag Protocol Extractor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Loading\n",
    "\n",
    "First, we'll import the necessary libraries and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "# Configure pandas to display more columns and rows\n",
    "pd.set_option(\"display.max_columns\", 30)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "\n",
    "# Import the Bundestag Protocol Extractor utilities\n",
    "from bundestag_protocol_extractor.utils.pandas_helper import BundestagDataFrames\n",
    "from bundestag_protocol_extractor.utils.data_quality import DataQualityReporter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "Now we'll load the extracted data from the CSV files. You can specify the data directory and the base filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the data directory\n",
    "data_dir = \"../output\"\n",
    "\n",
    "# Create a helper instance\n",
    "btdf = BundestagDataFrames(data_dir=data_dir)\n",
    "\n",
    "# Load all available dataframes\n",
    "# You can optionally specify a base filename if you have multiple exports\n",
    "dataframes = btdf.load_csv_data()\n",
    "\n",
    "# List the loaded dataframes\n",
    "print(f\"Loaded {len(dataframes)} dataframes:\")\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"- {name}: {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data structure\n",
    "\n",
    "Let's examine the structure of the speech data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the speeches dataframe\n",
    "df_speeches = btdf.get_dataframe(\"speeches\")\n",
    "\n",
    "# Display the first few rows\n",
    "df_speeches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the extraction quality metrics that are available in the speeches dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display extraction method distribution\n",
    "extraction_methods = df_speeches[\"extraction_method\"].value_counts()\n",
    "print(\"Extraction Methods:\")\n",
    "print(extraction_methods)\n",
    "print(\"\\nPercentages:\")\n",
    "print(extraction_methods / len(df_speeches) * 100)\n",
    "\n",
    "# Display extraction status distribution\n",
    "extraction_status = df_speeches[\"extraction_status\"].value_counts()\n",
    "print(\"\\nExtraction Status:\")\n",
    "print(extraction_status)\n",
    "print(\"\\nPercentages:\")\n",
    "print(extraction_status / len(df_speeches) * 100)\n",
    "\n",
    "# Display confidence score statistics\n",
    "print(\"\\nConfidence Score Statistics:\")\n",
    "print(df_speeches[\"extraction_confidence\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an integrated dataframe\n",
    "\n",
    "Now let's create an integrated dataframe that combines speeches with related entities like persons and protocols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an integrated dataframe\n",
    "df_integrated = btdf.create_integrated_speeches_df()\n",
    "\n",
    "# Display the first few rows\n",
    "df_integrated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter data by extraction quality\n",
    "\n",
    "Now let's filter the data to include only high-quality speeches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for high-quality speeches (XML extracted, complete)\n",
    "high_quality = btdf.filter_high_quality(df_integrated)\n",
    "print(\n",
    "    f\"High-quality speeches: {len(high_quality)} out of {len(df_integrated)} ({len(high_quality)/len(df_integrated)*100:.1f}%)\"\n",
    ")\n",
    "\n",
    "# Filter by minimum confidence score\n",
    "medium_quality = btdf.filter_by_confidence(df_integrated, min_confidence=0.5)\n",
    "print(\n",
    "    f\"Medium-quality speeches: {len(medium_quality)} out of {len(df_integrated)} ({len(medium_quality)/len(df_integrated)*100:.1f}%)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate quality visualizations\n",
    "\n",
    "Let's use the DataQualityReporter to generate visualizations of extraction quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a quality reporter\n",
    "reporter = DataQualityReporter(output_dir=data_dir)\n",
    "\n",
    "# Generate quality report\n",
    "quality_report = reporter.generate_quality_report(\n",
    "    df_speeches=df_integrated, protocol_metadata=btdf.get_dataframe(\"protocols\")\n",
    ")\n",
    "\n",
    "# Generate visualizations (but don't save to disk in the notebook)\n",
    "visualizations = reporter.generate_quality_visualizations(\n",
    "    df_speeches=df_integrated, base_filename=\"bundestag_example\", save_plots=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display some of the visualizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dashboard visualization\n",
    "plt.figure(figsize=(16, 12))\n",
    "visualizations[\"dashboard\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze speech length by extraction method\n",
    "\n",
    "Let's analyze how speech length varies by extraction method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add text length if not already there\n",
    "if \"text_length\" not in df_integrated.columns and \"text\" in df_integrated.columns:\n",
    "    df_integrated[\"text_length\"] = df_integrated[\"text\"].str.len()\n",
    "\n",
    "# Create a box plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = sns.boxplot(\n",
    "    x=\"extraction_method\", y=\"text_length\", data=df_integrated, palette=\"Set3\"\n",
    ")\n",
    "ax.set_title(\"Speech Length by Extraction Method\", fontsize=16)\n",
    "ax.set_xlabel(\"Extraction Method\", fontsize=14)\n",
    "ax.set_ylabel(\"Text Length (characters)\", fontsize=14)\n",
    "\n",
    "# Add mean values as text annotations\n",
    "for i, method in enumerate(df_integrated[\"extraction_method\"].unique()):\n",
    "    method_data = df_integrated[df_integrated[\"extraction_method\"] == method][\n",
    "        \"text_length\"\n",
    "    ]\n",
    "    mean_val = method_data.mean()\n",
    "    ax.text(\n",
    "        i,\n",
    "        mean_val,\n",
    "        f\"Mean: {int(mean_val)}\",\n",
    "        horizontalalignment=\"center\",\n",
    "        size=\"medium\",\n",
    "        color=\"black\",\n",
    "        weight=\"semibold\",\n",
    "    )\n",
    "\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze data by party\n",
    "\n",
    "Let's analyze the data by political party."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get party statistics\n",
    "party_stats = btdf.get_party_stats(df_integrated)\n",
    "\n",
    "# Print party counts\n",
    "print(\"Speech count by party:\")\n",
    "for party, count in party_stats.get(\"party_counts\", {}).items():\n",
    "    percentage = party_stats.get(\"party_percentages\", {}).get(party, 0)\n",
    "    print(f\"{party}: {count} speeches ({percentage:.1f}%)\")\n",
    "\n",
    "# Create a bar chart of speech count by party\n",
    "plt.figure(figsize=(12, 6))\n",
    "parties = list(party_stats.get(\"party_counts\", {}).keys())\n",
    "counts = list(party_stats.get(\"party_counts\", {}).values())\n",
    "\n",
    "# Sort by count (descending)\n",
    "sorted_indices = np.argsort(counts)[::-1]\n",
    "sorted_parties = [parties[i] for i in sorted_indices]\n",
    "sorted_counts = [counts[i] for i in sorted_indices]\n",
    "\n",
    "ax = sns.barplot(x=sorted_parties, y=sorted_counts, palette=\"Set3\")\n",
    "ax.set_title(\"Speech Count by Party\", fontsize=16)\n",
    "ax.set_xlabel(\"Party\", fontsize=14)\n",
    "ax.set_ylabel(\"Number of Speeches\", fontsize=14)\n",
    "\n",
    "# Add count labels\n",
    "for i, count in enumerate(sorted_counts):\n",
    "    ax.text(i, count + 5, str(count), ha=\"center\", va=\"bottom\", fontsize=10)\n",
    "\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze extraction method by party\n",
    "\n",
    "Let's see if there are differences in extraction methods across parties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of extraction method percentages by party\n",
    "method_percentages = {}\n",
    "for party, methods in party_stats.get(\"party_methods\", {}).items():\n",
    "    for method, percentage in methods.get(\"percentages\", {}).items():\n",
    "        if method not in method_percentages:\n",
    "            method_percentages[method] = {}\n",
    "        method_percentages[method][party] = percentage\n",
    "\n",
    "# Convert to dataframe\n",
    "df_methods = pd.DataFrame(method_percentages)\n",
    "\n",
    "# Display the dataframe\n",
    "print(\"Extraction method percentages by party:\")\n",
    "print(df_methods)\n",
    "\n",
    "# Create a stacked bar chart\n",
    "plt.figure(figsize=(14, 8))\n",
    "df_methods.plot(kind=\"bar\", stacked=True, figsize=(14, 8), colormap=\"Set3\")\n",
    "plt.title(\"Extraction Method Distribution by Party\", fontsize=16)\n",
    "plt.xlabel(\"Party\", fontsize=14)\n",
    "plt.ylabel(\"Percentage\", fontsize=14)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.legend(title=\"Extraction Method\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze speech length distribution\n",
    "\n",
    "Let's examine the distribution of speech lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get speech length bins\n",
    "length_bins = btdf.get_speech_length_bins(df_integrated, bin_size=500, max_length=10000)\n",
    "\n",
    "# Display the binned data\n",
    "print(\"Speech length distribution:\")\n",
    "print(length_bins)\n",
    "\n",
    "# Create a stacked bar chart of speech length bins\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Get columns that contain counts (not percentages)\n",
    "count_columns = [\n",
    "    col for col in length_bins.columns if not col.endswith(\"_pct\") and col != \"total\"\n",
    "]\n",
    "\n",
    "# Plot the stacked bar chart\n",
    "length_bins[count_columns].plot(\n",
    "    kind=\"bar\", stacked=True, figsize=(14, 8), colormap=\"Set3\"\n",
    ")\n",
    "plt.title(\"Speech Length Distribution by Extraction Method\", fontsize=16)\n",
    "plt.xlabel(\"Speech Length (characters)\", fontsize=14)\n",
    "plt.ylabel(\"Number of Speeches\", fontsize=14)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.legend(title=\"Extraction Method\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a multi-index dataframe for hierarchical analysis\n",
    "\n",
    "Let's create a multi-index dataframe that allows for hierarchical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a multi-index dataframe\n",
    "df_multi = btdf.create_multi_index_df()\n",
    "\n",
    "# Display the first few rows\n",
    "df_multi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the multi-index dataframe, we can easily analyze data at different hierarchical levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get statistics by protocol\n",
    "protocol_stats = df_multi.groupby(level=0).agg(\n",
    "    {\n",
    "        \"text_length\": [\"count\", \"mean\", \"median\", \"min\", \"max\"],\n",
    "        \"extraction_confidence\": [\"mean\", \"median\"],\n",
    "        \"is_xml_extracted\": \"mean\",  # Proportion of XML extracted speeches\n",
    "        \"is_complete\": \"mean\",  # Proportion of complete extractions\n",
    "        \"is_high_confidence\": \"mean\",  # Proportion of high confidence extractions\n",
    "    }\n",
    ")\n",
    "\n",
    "# Display the protocol statistics\n",
    "protocol_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the report and visualizations\n",
    "\n",
    "Finally, let's save the quality report and visualizations to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the quality report\n",
    "report_path = reporter.save_quality_report(quality_report, \"bundestag_quality_report\")\n",
    "print(f\"Saved quality report to {report_path}\")\n",
    "\n",
    "# Generate and save visualizations\n",
    "visualizations = reporter.generate_quality_visualizations(\n",
    "    df_speeches=df_integrated, base_filename=\"bundestag_quality\", save_plots=True\n",
    ")\n",
    "print(f\"Saved {len(visualizations)} visualizations\")\n",
    "\n",
    "# Create an HTML report\n",
    "html_path = reporter.create_html_report(\n",
    "    report=quality_report,\n",
    "    visualizations=visualizations,\n",
    "    filename=\"bundestag_quality_report.html\",\n",
    ")\n",
    "print(f\"Created HTML report at {html_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}